"""
Production Security Audit - Real Issues Only
============================================
Focuses on actual security vulnerabilities that would impact production deployment.
Filters out false positives from development tools.
"""

import os
import re
import glob
from typing import List, Dict, Any

class ProductionSecurityAuditor:
    """
    Audits for real security issues that would block production deployment.
    Ignores false positives from development and testing tools.
    """
    
    def __init__(self):
        self.critical_issues = []
        self.high_issues = []
        self.medium_issues = []
        
    def audit_production_readiness(self) -> Dict[str, Any]:
        """Comprehensive production readiness security audit"""
        
        print("=== PRODUCTION SECURITY AUDIT ===")
        
        # Check for actual security vulnerabilities
        self._check_secrets_exposure()
        self._check_input_validation()
        self._check_authentication_bypass()
        self._check_insecure_defaults()
        self._check_error_information_disclosure()
        
        return self._generate_report()
    
    def _check_secrets_exposure(self):
        """Check for exposed secrets that would compromise production"""
        
        print("ðŸ” Checking for exposed secrets...")
        
        # Files to check (exclude test and audit files)
        exclude_files = ['security_audit.py', 'test_', '_test.py', 'production_security_audit.py']
        python_files = [f for f in glob.glob('*.py') 
                       if not any(exclude in f for exclude in exclude_files)]
        
        dangerous_patterns = [
            (r'password\s*=\s*["\'][^"\']{8,}["\'](?!\s*#.*(?:fallback|dev|test))', 'Production hardcoded password'),
            (r'api[_-]?key\s*=\s*["\'][a-zA-Z0-9]{20,}["\']', 'Hardcoded API key'),
            (r'secret\s*=\s*["\'][a-zA-Z0-9]{16,}["\']', 'Hardcoded secret'),
            (r'bolt://[^:]+:[^@]+@[^/]+', 'Database credentials in connection string')
        ]
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern, description in dangerous_patterns:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        
                        # Skip if it's clearly a development fallback with warnings
                        context_lines = content.split('\n')[max(0, line_num-3):line_num+2]
                        context = '\n'.join(context_lines)
                        
                        if ('fallback' in context.lower() or 
                            'development' in context.lower() or
                            'warning' in context.lower()):
                            continue  # Skip development fallbacks
                        
                        self.critical_issues.append({
                            'file': file_path,
                            'line': line_num,
                            'issue': description,
                            'severity': 'CRITICAL'
                        })
            except Exception as e:
                print(f"Could not scan {file_path}: {e}")
    
    def _check_input_validation(self):
        """Check for missing input validation that could lead to injection attacks"""
        
        print("ðŸ” Checking input validation...")
        
        # Look for user input handling without validation
        validation_patterns = [
            (r'st\.text_input\([^)]+\)', 'Streamlit text input'),
            (r'st\.selectbox\([^)]+\)', 'Streamlit selectbox'),
            (r'st\.number_input\([^)]+\)', 'Streamlit number input'),
            (r'request\.get\([^)]+\)', 'HTTP request parameter'),
            (r'request\.form\[[^]]+\]', 'Form data access')
        ]
        
        python_files = glob.glob('streamlit_*.py')  # Focus on user-facing files
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern, description in validation_patterns:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        
                        # Check if there's validation nearby
                        surrounding_lines = content.split('\n')[max(0, line_num-5):line_num+5]
                        surrounding_text = '\n'.join(surrounding_lines)
                        
                        # Look for validation keywords
                        has_validation = any(keyword in surrounding_text.lower() 
                                           for keyword in ['validate', 'sanitize', 'clean', 'strip', 'escape'])
                        
                        if not has_validation:
                            self.medium_issues.append({
                                'file': file_path,
                                'line': line_num,
                                'issue': f'Unvalidated {description}',
                                'severity': 'MEDIUM'
                            })
            except Exception as e:
                print(f"Could not scan {file_path}: {e}")
    
    def _check_authentication_bypass(self):
        """Check for authentication bypass vulnerabilities"""
        
        print("ðŸ” Checking authentication...")
        
        # For now, we don't have authentication, which is actually a medium risk for production
        if not self._has_authentication():
            self.medium_issues.append({
                'file': 'platform-wide',
                'line': 0,
                'issue': 'No authentication system implemented',
                'severity': 'MEDIUM'
            })
    
    def _check_insecure_defaults(self):
        """Check for insecure default configurations"""
        
        print("ðŸ” Checking insecure defaults...")
        
        # Check for debug mode enabled
        python_files = glob.glob('*.py')
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if 'debug=True' in content.lower() or 'DEBUG=True' in content:
                    line_num = content.lower().find('debug=true')
                    if line_num != -1:
                        line_num = content[:line_num].count('\n') + 1
                        self.high_issues.append({
                            'file': file_path,
                            'line': line_num,
                            'issue': 'Debug mode enabled in production code',
                            'severity': 'HIGH'
                        })
            except Exception as e:
                continue
    
    def _check_error_information_disclosure(self):
        """Check for detailed error messages that could help attackers"""
        
        print("ðŸ” Checking error information disclosure...")
        
        # Look for detailed tracebacks or error messages exposed to users
        error_patterns = [
            (r'traceback\.print_exc\(\)', 'Traceback printed to user'),
            (r'except.*:\s*print\(.*\)', 'Exception details printed'),
            (r'st\.error\(.*traceback', 'Streamlit error with traceback')
        ]
        
        python_files = glob.glob('streamlit_*.py')
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                for pattern, description in error_patterns:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        line_num = content[:match.start()].count('\n') + 1
                        self.medium_issues.append({
                            'file': file_path,
                            'line': line_num,
                            'issue': description,
                            'severity': 'MEDIUM'
                        })
            except Exception as e:
                continue
    
    def _has_authentication(self) -> bool:
        """Check if the platform has any authentication mechanism"""
        
        auth_indicators = ['login', 'authenticate', 'session', 'user_id', 'token']
        
        python_files = glob.glob('*.py')
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().lower()
                
                if any(indicator in content for indicator in auth_indicators):
                    return True
            except Exception:
                continue
        
        return False
    
    def _generate_report(self) -> Dict[str, Any]:
        """Generate the final security assessment report"""
        
        total_issues = len(self.critical_issues) + len(self.high_issues) + len(self.medium_issues)
        
        # Calculate security score (100 - points deducted for issues)
        score = max(0, 100 - (len(self.critical_issues) * 40) - 
                   (len(self.high_issues) * 20) - (len(self.medium_issues) * 5))
        
        # Determine deployment readiness
        deployment_ready = (len(self.critical_issues) == 0 and len(self.high_issues) == 0)
        
        print(f"\n=== PRODUCTION SECURITY ASSESSMENT ===")
        print(f"Security Score: {score}/100")
        print(f"Critical Issues: {len(self.critical_issues)}")
        print(f"High Issues: {len(self.high_issues)}")  
        print(f"Medium Issues: {len(self.medium_issues)}")
        print(f"Deployment Ready: {'YES' if deployment_ready else 'NO'}")
        
        if self.critical_issues:
            print(f"\nCRITICAL ISSUES (BLOCK DEPLOYMENT):")
            for issue in self.critical_issues:
                print(f"  {issue['file']}:{issue['line']} - {issue['issue']}")
        
        if self.high_issues:
            print(f"\nHIGH ISSUES (FIX BEFORE PRODUCTION):")
            for issue in self.high_issues:
                print(f"  {issue['file']}:{issue['line']} - {issue['issue']}")
        
        if self.medium_issues:
            print(f"\nMEDIUM ISSUES (ADDRESS FOR HARDENING):")
            for issue in self.medium_issues[:3]:  # Show first 3
                print(f"  {issue['file']}:{issue['line']} - {issue['issue']}")
            if len(self.medium_issues) > 3:
                print(f"  ... and {len(self.medium_issues) - 3} more medium issues")
        
        return {
            'security_score': score,
            'deployment_ready': deployment_ready,
            'critical_issues': len(self.critical_issues),
            'high_issues': len(self.high_issues),
            'medium_issues': len(self.medium_issues),
            'total_issues': total_issues,
            'recommendation': self._get_deployment_recommendation(deployment_ready, score)
        }
    
    def _get_deployment_recommendation(self, deployment_ready: bool, score: int) -> str:
        """Get deployment recommendation based on security assessment"""
        
        if not deployment_ready:
            return "BLOCK: Fix critical/high issues before deployment"
        elif score >= 80:
            return "PROCEED: Good security posture for demo deployment"
        elif score >= 60:
            return "CAUTION: Address medium issues for production use"
        else:
            return "REVIEW: Multiple security concerns need attention"

if __name__ == "__main__":
    auditor = ProductionSecurityAuditor()
    report = auditor.audit_production_readiness()
    
    print(f"\n=== FINAL RECOMMENDATION ===")
    print(f"{report['recommendation']}")